# -*- coding: utf-8 -*-
"""pro_2021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m9Dvffd37Y9SBzZtC9csXCkB4afZYtNU
"""

import numpy as np
import scipy
import matplotlib
from matplotlib import pyplot as plt
import os
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D
from sklearn.model_selection import train_test_split
from keras.optimizers import SGD, Adam
from keras import backend as K
from sklearn import preprocessing
from keras.utils import np_utils
#from sklearn.cross_validation import StratifiedKFold
import os, math
import gdal
from copy import deepcopy
import pandas as pd
from numpy import save
!pip install patchify
from patchify import patchify, unpatchify

def readraster(file):
    dataSource = gdal.Open(file)
    band = dataSource.ReadAsArray()
    return(dataSource, band)

os.chdir("/content/drive/MyDrive/Major_project/2021/")
# Input land cover GeoTIFF for two time period
file1 = "clip_LC08_L1TP_137042_20210213_20210304_01_T1_Bstack_raster.tif"
file2 = "classify_area.tif"

ds_lc1, arr_lc1 = readraster(file1)
ds_lc2, arr_lc2 = readraster(file2)

print(np.count_nonzero(np.isnan(arr_lc1).any())) #check if there is any null value
print(np.count_nonzero(np.isnan(arr_lc1))) # count the total number of nan values
print(np.count_nonzero(~np.isnan(arr_lc1))) # count the total number of non-nan values

arr_lc1[np.isnan(arr_lc1)]=0 #replace nan values to 0

image = arr_lc1
image = np.reshape(image, (image.shape[1],image.shape[2], image.shape[0]))

print(image.shape)

newX = np.reshape(image, (-1, image.shape[2])) 
print(newX.shape)

scaler = preprocessing.StandardScaler().fit(newX)  
newX = scaler.transform(newX)

newX = np.reshape(newX, (image.shape[0],image.shape[1],image.shape[2]))

image_patches = patchify(newX, (5,5,7), step=1)

class_patches = patchify(arr_lc2, (5,5), step=1)

image_patches = np.reshape(image_patches, (image_patches.shape[0]*image_patches.shape[1]* image_patches.shape[2],image_patches.shape[3],image_patches.shape[4],image_patches.shape[5]))

class_patches1 = np.reshape(class_patches, (class_patches.shape[0] * class_patches.shape[1], class_patches.shape[2], class_patches.shape[3]))

print(image_patches.shape)

print(class_patches1.shape)

import matplotlib.pyplot as plt

plt.subplot(121)
plt.imshow(arr_lc2,cmap="hot")

train_center_pixel= []
x = 0
for i in range(241657):
    train_center_pixel.append(class_patches1[x][1][1])
    x= x+1

train_center_pixel = np.array(train_center_pixel)

(unique, counts) = np.unique(arr_lc2, return_counts=True)
class_patches = np.array((unique, counts)).T
print(class_patches)

print(arr_lc2.shape)

class_new=(arr_lc2 == 4).astype(int) #for built-up areas

print(class_new.shape)

(unique, counts) = np.unique(class_new, return_counts=True)
class_patches = np.array((unique, counts)).T
print(class_patches)

plt.subplot(121)
plt.imshow(class_new,cmap="hot")

from PIL import Image

import matplotlib
matplotlib.image.imsave('/content/drive/MyDrive/Major_project/2021/built-up_area.tiff',class_new)



class_new=(arr_lc2 == 3).astype(int) #for agricultural areas

print(class_new.shape)

(unique, counts) = np.unique(class_new, return_counts=True)
class_patches = np.array((unique, counts)).T
print(class_patches)

plt.subplot(121)
plt.imshow(class_new,cmap="hot")

from PIL import Image

import matplotlib
matplotlib.image.imsave('/content/drive/MyDrive/Major_project/2021/agricultural_area.tiff',class_new)



class_new=(arr_lc2 == 2).astype(int) #for veg_land areas

print(class_new.shape)

(unique, counts) = np.unique(class_new, return_counts=True)
class_patches = np.array((unique, counts)).T
print(class_patches)

plt.subplot(121)
plt.imshow(class_new,cmap="hot")

from PIL import Image

import matplotlib
matplotlib.image.imsave('/content/drive/MyDrive/Major_project/2021/veg_land_area.tiff',class_new)



class_new=(arr_lc2 == 1).astype(int) #for water areas

print(class_new.shape)

(unique, counts) = np.unique(class_new, return_counts=True)
class_patches = np.array((unique, counts)).T
print(class_patches)

plt.subplot(121)
plt.imshow(class_new,cmap="hot")

from PIL import Image

import matplotlib
matplotlib.image.imsave('/content/drive/MyDrive/Major_project/2021/water_area.tiff',class_new)



print(class_patches.shape)

print(image_patches.shape)
print(train_center_pixel.shape)

#image_patches = np.reshape(image_patches, (image_patches.shape[0],image_patches.shape[3],image_patches.shape[2],image_patches.shape[1]))
#print("shape reshaspe :" +str(image_patches.shape))

print(image_patches.shape)
print(train_center_pixel.shape)

input_shape = image_patches[0].shape
print(input_shape)

testRatio=0.05
def splitTrainTestSet(X, y, testRatio=0.20):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=345,stratify=y)
    return X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test = splitTrainTestSet(image_patches, train_center_pixel, testRatio)

X_train.shape

X_train.mean()

X_train = X_train/0.008510392

from keras.layers import BatchNormalization

# convert class labels to on-hot encoding
y_train1 = np_utils.to_categorical(y_train)
print(y_train1.shape)

# Define the model
model = Sequential()
model.add(Conv1D(128, 1, activation='relu', input_shape=input_shape))
model.add(BatchNormalization())
model.add(Conv1D(128, 1, activation='relu', input_shape=input_shape))
model.add(BatchNormalization())
model.add(Conv1D(128, 1, activation='relu', input_shape=input_shape))
model.add(BatchNormalization())
model.add(Conv1D(256, 1, activation='relu', input_shape=input_shape))
model.add(BatchNormalization())
#model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dense(512, activation='relu'))
#model.add(Dropout(0.5))
model.add(Dense(5, activation='softmax'))

model.summary()

#sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)
#model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

history = model.fit(X_train, y_train1, batch_size=128, epochs=10) #model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5)

history.history['accuracy']

import matplotlib.pyplot as plt


plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['Train'], loc='upper left')
plt.show()